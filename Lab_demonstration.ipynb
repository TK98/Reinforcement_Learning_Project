{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning - Deep Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc69f22067705372",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fef7e20e54e6243b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1. Deep Q-Network (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-39519f4ab05eb2a1",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from project.environments.customEnvironments import WindyGridWorld\n",
    "# env = gym.envs.make(\"CartPole-v1\")\n",
    "# env = gym.envs.make(\"MountainCar-v0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env is a TimeLimit wrapper around an env, so use env.env to look into the env (but otherwise you can forget about this)\n",
    "# ??env.env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3eafd0ab49103f3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_DQN():\n",
    "    from DQN import DeepQN, LinearQN\n",
    "    from DQN import train_QNet\n",
    "    from DQN import run_episodes\n",
    "\n",
    "\n",
    "    # Let's run it!\n",
    "    num_episodes = 100\n",
    "    batch_size = 64\n",
    "    discount_factor = 0.8\n",
    "    learn_rate = 1e-3\n",
    "    num_hidden = 128\n",
    "    seed = 42  # This is not randomly chosen\n",
    "\n",
    "    # We will seed the algorithm (before initializing QNetwork!) for reproducibility\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    env.seed(seed)\n",
    "\n",
    "    my_DQN = DeepQN(in_features=4, out_features=2, discount_factor=discount_factor)\n",
    "    # my_DQN = LinearQN()\n",
    "    episode_durations = run_episodes(env, my_DQN, num_episodes, batch_size, learn_rate, semi_grad=True)\n",
    "\n",
    "    # And see the results\n",
    "    def smooth(x, N):\n",
    "        cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "        return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "    plt.plot(smooth(episode_durations, 10))\n",
    "    plt.title('Episode durations per episode')\n",
    "\n",
    "# run_DQN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Deep SARSA-Network (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_deepSARSA():\n",
    "    from DSN import SARSANetwork, run_episodes\n",
    "\n",
    "    # Let's run it!\n",
    "    num_episodes = 100\n",
    "    batch_size = 64\n",
    "    discount_factor = 0.8\n",
    "    learn_rate = 1e-3\n",
    "    num_hidden = 128\n",
    "    seed = 42  # This is not randomly chosen\n",
    "\n",
    "    # We will seed the algorithm (before initializing QNetwork!) for reproducibility\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    env.seed(seed)\n",
    "\n",
    "\n",
    "    my_DSN = SARSANetwork(in_features=4, num_hidden=num_hidden, out_features=2, discount_factor=discount_factor)\n",
    "    episode_durations = run_episodes(env, my_DSN, num_episodes, batch_size, learn_rate, semi_grad=False)\n",
    "    \n",
    "    # And see the results\n",
    "    def smooth(x, N):\n",
    "        cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "        return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "    plt.plot(smooth(episode_durations, 10))\n",
    "    plt.title('Episode durations per episode')\n",
    "\n",
    "# run_deepSARSA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.networks import SARSANetwork, DeepQNetwork\n",
    "from project.policies import EpsilonGreedyPolicy\n",
    "\n",
    "from project.train_network import train_episodes\n",
    "from project.test_network import test_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00839396  0.02602053 -0.0090631   0.003036  ]\n",
      " Episode 0 finished after 15 steps\n",
      " Episode 10 finished after 18 steps\n",
      " Episode 20 finished after 9 steps\n",
      " Episode 30 finished after 25 steps\n",
      " Episode 40 finished after 10 steps\n",
      " Episode 50 finished after 12 steps\n",
      " Episode 60 finished after 20 steps\n",
      " Episode 70 finished after 13 steps\n",
      " Episode 80 finished after 28 steps\n",
      " Episode 90 finished after 19 steps\n",
      " Episode 100 finished after 13 steps\n",
      " Episode 110 finished after 18 steps\n",
      " Episode 120 finished after 11 steps\n",
      " Episode 130 finished after 28 steps\n",
      " Episode 140 finished after 17 steps\n",
      " Episode 150 finished after 26 steps\n",
      " Episode 160 finished after 9 steps\n",
      " Episode 170 finished after 42 steps\n",
      " Episode 180 finished after 14 steps\n",
      " Episode 190 finished after 15 steps\n",
      " Episode 200 finished after 13 steps\n",
      " Episode 210 finished after 15 steps\n",
      " Episode 220 finished after 13 steps\n",
      " Episode 230 finished after 13 steps\n",
      " Episode 240 finished after 13 steps\n",
      " Episode 250 finished after 8 steps\n",
      " Episode 260 finished after 14 steps\n",
      " Episode 270 finished after 16 steps\n",
      " Episode 280 finished after 13 steps\n",
      " Episode 290 finished after 13 steps\n",
      " Episode 300 finished after 14 steps\n",
      " Episode 310 finished after 12 steps\n",
      " Episode 320 finished after 9 steps\n",
      " Episode 330 finished after 10 steps\n",
      " Episode 340 finished after 8 steps\n",
      " Episode 350 finished after 12 steps\n",
      " Episode 360 finished after 10 steps\n",
      " Episode 370 finished after 15 steps\n",
      " Episode 380 finished after 14 steps\n",
      " Episode 390 finished after 9 steps\n",
      " Episode 400 finished after 12 steps\n",
      " Episode 410 finished after 9 steps\n",
      " Episode 420 finished after 13 steps\n",
      " Episode 430 finished after 12 steps\n",
      " Episode 440 finished after 9 steps\n",
      " Episode 450 finished after 10 steps\n",
      " Episode 460 finished after 13 steps\n",
      " Episode 470 finished after 10 steps\n",
      " Episode 480 finished after 12 steps\n",
      " Episode 490 finished after 9 steps\n"
     ]
    }
   ],
   "source": [
    "# env = WindyGridWorld()\n",
    "env = gym.envs.make(\"CartPole-v1\")\n",
    "\n",
    "num_episodes = 500\n",
    "batch_size = 1\n",
    "discount_factor = 1\n",
    "learn_rate = 1e-3\n",
    "semi_grad = True\n",
    "use_replay = False\n",
    "seed = 42\n",
    "\n",
    "print(env.reset())\n",
    "dq_network = SARSANetwork(in_features=4, out_features=2, discount_factor=discount_factor)\n",
    "dq_policy = EpsilonGreedyPolicy(dq_network, steps_e=10000)\n",
    "episode_durations, losses = train_episodes(env, dq_policy, num_episodes, batch_size, learn_rate, semi_grad=semi_grad, use_replay=use_replay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "rl2020",
   "language": "python",
   "name": "rl2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
