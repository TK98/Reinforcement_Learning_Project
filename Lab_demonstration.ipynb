{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning - Deep Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc69f22067705372",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fef7e20e54e6243b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1. Deep Q-Network (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-39519f4ab05eb2a1",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wight\\Anaconda3\\envs\\rl2020\\lib\\site-packages\\gym\\envs\\registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from project.environments.customEnvironments import WindyGridWorld\n",
    "env = gym.envs.make(\"CartPole-v1\")\n",
    "# env = gym.envs.make(\"MountainCar-v0\")\n",
    "# env = WindyGridWorld()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.networks import SARSANetwork, DeepQNetwork\n",
    "from project.policies import EpsilonGreedyPolicy\n",
    "\n",
    "from project.train_network import train_episodes\n",
    "from project.test_network import test_episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3eafd0ab49103f3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode 0 finished after 12 steps\n",
      " Episode 10 finished after 39 steps\n",
      " Episode 20 finished after 325 steps\n",
      " Episode 30 finished after 92 steps\n",
      " Episode 40 finished after 300 steps\n",
      " Episode 50 finished after 378 steps\n",
      " Episode 60 finished after 20 steps\n",
      " Episode 70 finished after 125 steps\n",
      " Episode 80 finished after 61 steps\n",
      " Episode 90 finished after 80 steps\n",
      " Episode 100 finished after 14 steps\n",
      " Episode 110 finished after 498 steps\n",
      " Episode 120 finished after 240 steps\n",
      " Episode 130 finished after 85 steps\n",
      " Episode 140 finished after 61 steps\n",
      " Episode 150 finished after 181 steps\n",
      " Episode 160 finished after 452 steps\n",
      " Episode 170 finished after 162 steps\n",
      " Episode 180 finished after 159 steps\n",
      " Episode 190 finished after 235 steps\n",
      " Episode 200 finished after 60 steps\n",
      " Episode 210 finished after 170 steps\n",
      " Episode 220 finished after 132 steps\n",
      " Episode 230 finished after 251 steps\n",
      " Episode 240 finished after 151 steps\n",
      " Episode 250 finished after 219 steps\n",
      " Episode 260 finished after 120 steps\n",
      " Episode 270 finished after 75 steps\n",
      " Episode 280 finished after 151 steps\n",
      " Episode 290 finished after 250 steps\n",
      " Episode 300 finished after 176 steps\n",
      " Episode 310 finished after 131 steps\n",
      " Episode 320 finished after 108 steps\n",
      " Episode 330 finished after 170 steps\n",
      " Episode 340 finished after 204 steps\n",
      " Episode 350 finished after 186 steps\n",
      " Episode 360 finished after 35 steps\n",
      " Episode 370 finished after 211 steps\n",
      " Episode 380 finished after 332 steps\n",
      " Episode 390 finished after 119 steps\n",
      " Episode 400 finished after 341 steps\n",
      " Episode 410 finished after 198 steps\n",
      " Episode 420 finished after 138 steps\n",
      " Episode 430 finished after 119 steps\n",
      " Episode 440 finished after 263 steps\n",
      " Episode 450 finished after 168 steps\n",
      " Episode 460 finished after 66 steps\n",
      " Episode 470 finished after 146 steps\n",
      " Episode 480 finished after 142 steps\n",
      " Episode 490 finished after 265 steps\n",
      " Episode 500 finished after 154 steps\n",
      " Episode 510 finished after 182 steps\n",
      " Episode 520 finished after 179 steps\n",
      " Episode 530 finished after 141 steps\n",
      " Episode 540 finished after 300 steps\n",
      " Episode 550 finished after 155 steps\n",
      " Episode 560 finished after 221 steps\n",
      " Episode 570 finished after 208 steps\n",
      " Episode 580 finished after 143 steps\n",
      " Episode 590 finished after 117 steps\n",
      " Episode 600 finished after 276 steps\n",
      " Episode 610 finished after 40 steps\n",
      " Episode 620 finished after 162 steps\n",
      " Episode 630 finished after 152 steps\n",
      " Episode 640 finished after 153 steps\n",
      " Episode 650 finished after 147 steps\n",
      " Episode 660 finished after 225 steps\n",
      " Episode 670 finished after 160 steps\n",
      " Episode 680 finished after 193 steps\n",
      " Episode 690 finished after 198 steps\n",
      " Episode 700 finished after 170 steps\n",
      " Episode 710 finished after 173 steps\n",
      " Episode 720 finished after 178 steps\n",
      " Episode 730 finished after 198 steps\n",
      " Episode 740 finished after 183 steps\n",
      " Episode 750 finished after 38 steps\n",
      " Episode 760 finished after 194 steps\n",
      " Episode 770 finished after 153 steps\n",
      " Episode 780 finished after 287 steps\n",
      " Episode 790 finished after 161 steps\n",
      " Episode 800 finished after 201 steps\n",
      " Episode 810 finished after 166 steps\n",
      " Episode 820 finished after 170 steps\n",
      " Episode 830 finished after 185 steps\n",
      " Episode 840 finished after 166 steps\n",
      " Episode 850 finished after 185 steps\n",
      " Episode 860 finished after 246 steps\n",
      " Episode 870 finished after 171 steps\n",
      " Episode 880 finished after 143 steps\n",
      " Episode 890 finished after 212 steps\n",
      " Episode 900 finished after 441 steps\n",
      " Episode 910 finished after 234 steps\n",
      " Episode 920 finished after 500 steps\n",
      " Episode 930 finished after 173 steps\n",
      " Episode 940 finished after 100 steps\n",
      " Episode 950 finished after 145 steps\n",
      " Episode 960 finished after 500 steps\n",
      " Episode 970 finished after 162 steps\n",
      " Episode 980 finished after 500 steps\n",
      " Episode 990 finished after 353 steps\n",
      " Episode 0 finished after 182 steps obtaining 182.0 reward\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([182, 220, 194, 491, 259, 224, 210, 273, 128, 219],\n",
       " [182.0, 220.0, 194.0, 491.0, 259.0, 224.0, 210.0, 273.0, 128.0, 219.0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's run it!\n",
    "num_episodes = 1000\n",
    "batch_size = 64\n",
    "discount_factor = 0.75\n",
    "\n",
    "\n",
    "\n",
    "learn_rate = 1e-3\n",
    "lr_step_size = 500\n",
    "lr_gamma = 0.1\n",
    "\n",
    "semi_grad=False\n",
    "use_replay=True\n",
    "\n",
    "architecture = [128, 256, 128]\n",
    "\n",
    "\n",
    "dq_network = DeepQNetwork(in_features=4, out_features=2, discount_factor=discount_factor, architecture=architecture)\n",
    "dq_policy = EpsilonGreedyPolicy(dq_network, end_e=0.01)\n",
    "episode_durations, losses, episode_rewards = train_episodes(env, dq_policy, num_episodes, batch_size, learn_rate, semi_grad=semi_grad, use_replay=use_replay,\n",
    "                                                           lr_step_size=lr_step_size, lr_gamma=lr_gamma)\n",
    "\n",
    "test_episodes(env, dq_policy, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Deep SARSA-Network (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_deepSARSA():\n",
    "    from DSN import SARSANetwork, run_episodes\n",
    "\n",
    "    # Let's run it!\n",
    "    num_episodes = 100\n",
    "    batch_size = 64\n",
    "    discount_factor = 0.8\n",
    "    learn_rate = 1e-3\n",
    "    num_hidden = 128\n",
    "    seed = 42  # This is not randomly chosen\n",
    "\n",
    "    # We will seed the algorithm (before initializing QNetwork!) for reproducibility\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    env.seed(seed)\n",
    "\n",
    "\n",
    "    my_DSN = SARSANetwork(in_features=4, num_hidden=num_hidden, out_features=2, discount_factor=discount_factor)\n",
    "    episode_durations = run_episodes(env, my_DSN, num_episodes, batch_size, learn_rate, semi_grad=False)\n",
    "    \n",
    "    # And see the results\n",
    "    def smooth(x, N):\n",
    "        cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "        return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "    plt.plot(smooth(episode_durations, 10))\n",
    "    plt.title('Episode durations per episode')\n",
    "\n",
    "# run_deepSARSA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.networks import SARSANetwork, DeepQNetwork\n",
    "from project.policies import EpsilonGreedyPolicy\n",
    "\n",
    "from project.train_network import train_episodes\n",
    "from project.test_network import test_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00839396  0.02602053 -0.0090631   0.003036  ]\n",
      " Episode 0 finished after 15 steps\n",
      " Episode 10 finished after 18 steps\n",
      " Episode 20 finished after 9 steps\n",
      " Episode 30 finished after 25 steps\n",
      " Episode 40 finished after 10 steps\n",
      " Episode 50 finished after 12 steps\n",
      " Episode 60 finished after 20 steps\n",
      " Episode 70 finished after 13 steps\n",
      " Episode 80 finished after 28 steps\n",
      " Episode 90 finished after 19 steps\n",
      " Episode 100 finished after 13 steps\n",
      " Episode 110 finished after 18 steps\n",
      " Episode 120 finished after 11 steps\n",
      " Episode 130 finished after 28 steps\n",
      " Episode 140 finished after 17 steps\n",
      " Episode 150 finished after 26 steps\n",
      " Episode 160 finished after 9 steps\n",
      " Episode 170 finished after 42 steps\n",
      " Episode 180 finished after 14 steps\n",
      " Episode 190 finished after 15 steps\n",
      " Episode 200 finished after 13 steps\n",
      " Episode 210 finished after 15 steps\n",
      " Episode 220 finished after 13 steps\n",
      " Episode 230 finished after 13 steps\n",
      " Episode 240 finished after 13 steps\n",
      " Episode 250 finished after 8 steps\n",
      " Episode 260 finished after 14 steps\n",
      " Episode 270 finished after 16 steps\n",
      " Episode 280 finished after 13 steps\n",
      " Episode 290 finished after 13 steps\n",
      " Episode 300 finished after 14 steps\n",
      " Episode 310 finished after 12 steps\n",
      " Episode 320 finished after 9 steps\n",
      " Episode 330 finished after 10 steps\n",
      " Episode 340 finished after 8 steps\n",
      " Episode 350 finished after 12 steps\n",
      " Episode 360 finished after 10 steps\n",
      " Episode 370 finished after 15 steps\n",
      " Episode 380 finished after 14 steps\n",
      " Episode 390 finished after 9 steps\n",
      " Episode 400 finished after 12 steps\n",
      " Episode 410 finished after 9 steps\n",
      " Episode 420 finished after 13 steps\n",
      " Episode 430 finished after 12 steps\n",
      " Episode 440 finished after 9 steps\n",
      " Episode 450 finished after 10 steps\n",
      " Episode 460 finished after 13 steps\n",
      " Episode 470 finished after 10 steps\n",
      " Episode 480 finished after 12 steps\n",
      " Episode 490 finished after 9 steps\n"
     ]
    }
   ],
   "source": [
    "# env = WindyGridWorld()\n",
    "env = gym.envs.make(\"CartPole-v1\")\n",
    "\n",
    "num_episodes = 500\n",
    "batch_size = 1\n",
    "discount_factor = 1\n",
    "learn_rate = 1e-3\n",
    "semi_grad = True\n",
    "use_replay = False\n",
    "seed = 42\n",
    "\n",
    "print(env.reset())\n",
    "dq_network = SARSANetwork(in_features=4, out_features=2, discount_factor=discount_factor)\n",
    "dq_policy = EpsilonGreedyPolicy(dq_network, steps_e=10000)\n",
    "episode_durations, losses = train_episodes(env, dq_policy, num_episodes, batch_size, learn_rate, semi_grad=semi_grad, use_replay=use_replay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "rl2020",
   "language": "python",
   "name": "rl2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
