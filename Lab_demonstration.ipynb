{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning - Deep Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc69f22067705372",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fef7e20e54e6243b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1. Deep Q-Network (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-39519f4ab05eb2a1",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from project.environments.customEnvironments import WindyGridWorld\n",
    "env = gym.envs.make(\"CartPole-v1\")\n",
    "# env = gym.envs.make(\"MountainCar-v0\")\n",
    "# env = WindyGridWorld()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.networks import SARSANetwork, DeepQNetwork\n",
    "from project.policies import EpsilonGreedyPolicy\n",
    "\n",
    "from project.train_network import train_episodes\n",
    "from project.test_network import test_episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3eafd0ab49103f3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[99m Episode 0 finished after 10 steps\n",
      "\u001b[99m Episode 10 finished after 10 steps\n",
      "\u001b[92m Episode 20 finished after 301 steps\n",
      "\u001b[92m Episode 30 finished after 240 steps\n",
      "\u001b[99m Episode 40 finished after 42 steps\n",
      "\u001b[99m Episode 50 finished after 158 steps\n",
      "\u001b[99m Episode 60 finished after 13 steps\n",
      "\u001b[99m Episode 70 finished after 131 steps\n",
      "\u001b[99m Episode 80 finished after 98 steps\n",
      "\u001b[99m Episode 90 finished after 144 steps\n",
      "\u001b[92m Episode 100 finished after 500 steps\n",
      "\u001b[99m Episode 110 finished after 47 steps\n",
      "\u001b[99m Episode 120 finished after 50 steps\n",
      "\u001b[99m Episode 130 finished after 95 steps\n",
      "\u001b[99m Episode 140 finished after 158 steps\n",
      "\u001b[99m Episode 150 finished after 147 steps\n",
      "\u001b[99m Episode 160 finished after 40 steps\n",
      "\u001b[99m Episode 170 finished after 126 steps\n",
      "\u001b[99m Episode 180 finished after 113 steps\n",
      "\u001b[99m Episode 190 finished after 68 steps\n",
      "\u001b[99m Episode 200 finished after 125 steps\n",
      "\u001b[99m Episode 210 finished after 68 steps\n",
      "\u001b[92m Episode 220 finished after 270 steps\n",
      "\u001b[99m Episode 230 finished after 146 steps\n",
      "\u001b[99m Episode 240 finished after 46 steps\n",
      "\u001b[92m Episode 250 finished after 198 steps\n",
      "\u001b[99m Episode 260 finished after 173 steps\n",
      "\u001b[92m Episode 270 finished after 197 steps\n",
      "\u001b[99m Episode 280 finished after 132 steps\n",
      "\u001b[99m Episode 290 finished after 141 steps\n",
      "\u001b[99m Episode 300 finished after 140 steps\n",
      "\u001b[92m Episode 310 finished after 231 steps\n",
      "\u001b[92m Episode 320 finished after 351 steps\n",
      "\u001b[92m Episode 330 finished after 270 steps\n",
      "\u001b[99m Episode 340 finished after 103 steps\n",
      "\u001b[99m Episode 350 finished after 26 steps\n",
      "\u001b[99m Episode 360 finished after 153 steps\n",
      "\u001b[99m Episode 370 finished after 46 steps\n",
      "\u001b[92m Episode 380 finished after 199 steps\n",
      "\u001b[92m Episode 390 finished after 278 steps\n",
      "\u001b[92m Episode 400 finished after 311 steps\n",
      "\u001b[99m Episode 410 finished after 58 steps\n",
      "\u001b[99m Episode 420 finished after 137 steps\n",
      "\u001b[99m Episode 430 finished after 12 steps\n",
      "\u001b[99m Episode 440 finished after 16 steps\n",
      "\u001b[92m Episode 450 finished after 218 steps\n",
      "\u001b[92m Episode 460 finished after 245 steps\n",
      "\u001b[99m Episode 470 finished after 92 steps\n",
      "\u001b[92m Episode 480 finished after 232 steps\n",
      "\u001b[99m Episode 490 finished after 113 steps\n",
      "\u001b[99m Episode 500 finished after 149 steps\n",
      "\u001b[99m Episode 510 finished after 127 steps\n",
      "\u001b[99m Episode 520 finished after 100 steps\n",
      "\u001b[99m Episode 530 finished after 109 steps\n",
      "\u001b[99m Episode 540 finished after 114 steps\n",
      "\u001b[99m Episode 550 finished after 126 steps\n",
      "\u001b[92m Episode 560 finished after 199 steps\n",
      "\u001b[99m Episode 570 finished after 151 steps\n",
      "\u001b[99m Episode 580 finished after 139 steps\n",
      "\u001b[99m Episode 590 finished after 96 steps\n",
      "\u001b[99m Episode 600 finished after 94 steps\n",
      "\u001b[99m Episode 610 finished after 121 steps\n",
      "\u001b[99m Episode 620 finished after 113 steps\n",
      "\u001b[99m Episode 630 finished after 127 steps\n",
      "\u001b[99m Episode 640 finished after 172 steps\n",
      "\u001b[99m Episode 650 finished after 98 steps\n",
      "\u001b[99m Episode 660 finished after 90 steps\n",
      "\u001b[99m Episode 670 finished after 68 steps\n",
      "\u001b[99m Episode 680 finished after 188 steps\n",
      "\u001b[99m Episode 690 finished after 140 steps\n",
      "\u001b[99m Episode 700 finished after 168 steps\n",
      "\u001b[99m Episode 710 finished after 119 steps\n",
      "\u001b[99m Episode 720 finished after 105 steps\n",
      "\u001b[99m Episode 730 finished after 178 steps\n",
      "\u001b[99m Episode 740 finished after 171 steps\n",
      "\u001b[92m Episode 750 finished after 207 steps\n",
      "\u001b[99m Episode 760 finished after 108 steps\n",
      "\u001b[99m Episode 770 finished after 147 steps\n",
      "\u001b[99m Episode 780 finished after 164 steps\n",
      "\u001b[99m Episode 790 finished after 92 steps\n",
      "\u001b[99m Episode 800 finished after 16 steps\n",
      "\u001b[99m Episode 810 finished after 104 steps\n",
      "\u001b[99m Episode 820 finished after 190 steps\n",
      "\u001b[99m Episode 830 finished after 132 steps\n",
      "\u001b[99m Episode 840 finished after 108 steps\n",
      "\u001b[99m Episode 850 finished after 138 steps\n",
      "\u001b[99m Episode 860 finished after 125 steps\n",
      "\u001b[99m Episode 870 finished after 139 steps\n",
      "\u001b[99m Episode 880 finished after 142 steps\n",
      "\u001b[99m Episode 890 finished after 142 steps\n",
      "\u001b[99m Episode 900 finished after 145 steps\n",
      "\u001b[99m Episode 910 finished after 149 steps\n",
      "\u001b[92m Episode 920 finished after 382 steps\n",
      "\u001b[99m Episode 930 finished after 103 steps\n",
      "\u001b[99m Episode 940 finished after 167 steps\n",
      "\u001b[92m Episode 950 finished after 247 steps\n",
      "\u001b[99m Episode 960 finished after 148 steps\n",
      "\u001b[92m Episode 970 finished after 218 steps\n",
      "\u001b[99m Episode 980 finished after 146 steps\n",
      "\u001b[99m Episode 990 finished after 149 steps\n",
      "\u001b[99m Episode 0 finished after 146 steps obtaining 146.0 reward\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([146, 166, 140, 144, 137, 136, 137, 151, 140, 130],\n",
       " [146.0, 166.0, 140.0, 144.0, 137.0, 136.0, 137.0, 151.0, 140.0, 130.0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's run it!\n",
    "num_episodes = 1000\n",
    "batch_size = 64\n",
    "discount_factor = 0.75\n",
    "\n",
    "\n",
    "\n",
    "learn_rate = 1e-3\n",
    "lr_step_size = 500\n",
    "lr_gamma = 0.1\n",
    "\n",
    "semi_grad=False\n",
    "use_replay=True\n",
    "\n",
    "architecture = [128, 256, 128]\n",
    "\n",
    "\n",
    "dq_network = DeepQNetwork(in_features=4, out_features=2, discount_factor=discount_factor, architecture=architecture)\n",
    "dq_policy = EpsilonGreedyPolicy(dq_network)\n",
    "dq_policy = EpsilonGreedyPolicy(dq_network, end_e=0.01)\n",
    "episode_durations, losses, episode_rewards, _ = train_episodes(env, dq_policy, num_episodes, batch_size, learn_rate, semi_grad=semi_grad, use_replay=use_replay,\n",
    "                                                           lr_step_size=lr_step_size, lr_gamma=lr_gamma)\n",
    "\n",
    "test_episodes(env, dq_policy, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Deep SARSA-Network (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_deepSARSA():\n",
    "    from DSN import SARSANetwork, run_episodes\n",
    "\n",
    "    # Let's run it!\n",
    "    num_episodes = 100\n",
    "    batch_size = 64\n",
    "    discount_factor = 0.8\n",
    "    learn_rate = 1e-3\n",
    "    num_hidden = 128\n",
    "    seed = 42  # This is not randomly chosen\n",
    "\n",
    "    # We will seed the algorithm (before initializing QNetwork!) for reproducibility\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    env.seed(seed)\n",
    "\n",
    "\n",
    "    my_DSN = SARSANetwork(in_features=4, num_hidden=num_hidden, out_features=2, discount_factor=discount_factor)\n",
    "    episode_durations = run_episodes(env, my_DSN, num_episodes, batch_size, learn_rate, semi_grad=False)\n",
    "    \n",
    "    # And see the results\n",
    "    def smooth(x, N):\n",
    "        cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "        return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "    plt.plot(smooth(episode_durations, 10))\n",
    "    plt.title('Episode durations per episode')\n",
    "\n",
    "# run_deepSARSA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.networks import SARSANetwork, DeepQNetwork\n",
    "from project.policies import EpsilonGreedyPolicy\n",
    "\n",
    "from project.train_network import train_episodes\n",
    "from project.test_network import test_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01642634 -0.04672059 -0.04208646  0.03716467]\n",
      "\u001b[99m Episode 0 finished after 21 steps\n",
      "\u001b[99m Episode 10 finished after 22 steps\n",
      "\u001b[99m Episode 20 finished after 19 steps\n",
      "\u001b[99m Episode 30 finished after 9 steps\n",
      "\u001b[99m Episode 40 finished after 31 steps\n",
      "\u001b[99m Episode 50 finished after 24 steps\n",
      "\u001b[99m Episode 60 finished after 22 steps\n",
      "\u001b[99m Episode 70 finished after 14 steps\n",
      "\u001b[99m Episode 80 finished after 22 steps\n",
      "\u001b[99m Episode 90 finished after 15 steps\n",
      "\u001b[99m Episode 100 finished after 18 steps\n",
      "\u001b[99m Episode 110 finished after 20 steps\n",
      "\u001b[99m Episode 120 finished after 12 steps\n",
      "\u001b[99m Episode 130 finished after 13 steps\n",
      "\u001b[99m Episode 140 finished after 11 steps\n",
      "\u001b[99m Episode 150 finished after 21 steps\n",
      "\u001b[99m Episode 160 finished after 12 steps\n",
      "\u001b[99m Episode 170 finished after 15 steps\n",
      "\u001b[99m Episode 180 finished after 18 steps\n",
      "\u001b[99m Episode 190 finished after 11 steps\n",
      "\u001b[99m Episode 200 finished after 17 steps\n",
      "\u001b[99m Episode 210 finished after 13 steps\n",
      "\u001b[99m Episode 220 finished after 21 steps\n",
      "\u001b[99m Episode 230 finished after 16 steps\n",
      "\u001b[99m Episode 240 finished after 13 steps\n",
      "\u001b[99m Episode 250 finished after 17 steps\n",
      "\u001b[99m Episode 260 finished after 17 steps\n",
      "\u001b[99m Episode 270 finished after 14 steps\n",
      "\u001b[99m Episode 280 finished after 11 steps\n",
      "\u001b[99m Episode 290 finished after 10 steps\n",
      "\u001b[99m Episode 300 finished after 10 steps\n",
      "\u001b[99m Episode 310 finished after 9 steps\n",
      "\u001b[99m Episode 320 finished after 11 steps\n",
      "\u001b[99m Episode 330 finished after 28 steps\n",
      "\u001b[99m Episode 340 finished after 12 steps\n",
      "\u001b[99m Episode 350 finished after 11 steps\n",
      "\u001b[99m Episode 360 finished after 11 steps\n",
      "\u001b[99m Episode 370 finished after 15 steps\n",
      "\u001b[99m Episode 380 finished after 19 steps\n",
      "\u001b[99m Episode 390 finished after 12 steps\n",
      "\u001b[99m Episode 400 finished after 13 steps\n",
      "\u001b[99m Episode 410 finished after 14 steps\n",
      "\u001b[99m Episode 420 finished after 9 steps\n",
      "\u001b[99m Episode 430 finished after 9 steps\n",
      "\u001b[99m Episode 440 finished after 11 steps\n",
      "\u001b[99m Episode 450 finished after 11 steps\n",
      "\u001b[99m Episode 460 finished after 11 steps\n",
      "\u001b[99m Episode 470 finished after 10 steps\n",
      "\u001b[99m Episode 480 finished after 11 steps\n",
      "\u001b[99m Episode 490 finished after 14 steps\n"
     ]
    }
   ],
   "source": [
    "# env = WindyGridWorld()\n",
    "env = gym.envs.make(\"CartPole-v1\")\n",
    "\n",
    "num_episodes = 500\n",
    "batch_size = 1\n",
    "discount_factor = 1\n",
    "learn_rate = 1e-3\n",
    "semi_grad = True\n",
    "use_replay = False\n",
    "seed = 42\n",
    "\n",
    "print(env.reset())\n",
    "dq_network = SARSANetwork(in_features=4, out_features=2, discount_factor=discount_factor)\n",
    "dq_policy = EpsilonGreedyPolicy(dq_network, steps_e=10000)\n",
    "episode_durations, losses, episode_rewards, _ = train_episodes(env, dq_policy, num_episodes, batch_size, learn_rate, semi_grad=semi_grad, use_replay=use_replay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
